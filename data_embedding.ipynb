{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083962d8",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Cada modelo tiene todos los vídeos y la etiqueta en la columna **shoot_zone**,  donde lanzamiento a la derecha es 0, al centro es 1 y a la izquierda  es 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcdd711",
   "metadata": {},
   "source": [
    "| Fichero                      | Modelo          | Comentarios sobre “\\_SUFIJO”                              |\n",
    "| ---------------------------- | --------------- | --------------------------------------------------------- |\n",
    "| **baseline\\_CASIAB.csv**     | Baseline        | Versión “base” (p.ej. GEINet simple) entrenada en CASIA-B |\n",
    "| **baseline\\_OUMVLP.csv**     | Baseline        | Igual que el anterior, pero pre-entrenado en OU-MVLP      |\n",
    "| **gaitgl.csv**               | GaitGL          | GaitGL estándar (dataset por defecto, p.ej. CASIA-B)      |\n",
    "| **gaitgl\\_OUMVLP.csv**       | GaitGL          | Pre-entrenado en OU-MVLP                                  |\n",
    "| **gaitgl\\_GREW\\.csv**        | GaitGL          | Pre-entrenado en GREW                                     |\n",
    "| **gaitgl\\_GREW\\_BNNeck.csv** | GaitGL + BNNeck | Mismo que el anterior, con cuello de batch-norm extra     |\n",
    "| **gaitpart.csv**             | GaitPart        | GaitPart estándar                                         |\n",
    "| **gaitpart\\_OUMVLP.csv**     | GaitPart        | Pre-entrenado en OU-MVLP                                  |\n",
    "| **gaitpart\\_GREW\\.csv**      | GaitPart        | Pre-entrenado en GREW                                     |\n",
    "| **gaitset.csv**              | GaitSet         | GaitSet estándar                                          |\n",
    "| **gaitset\\_OUMVLP.csv**      | GaitSet         | Pre-entrenado en OU-MVLP                                  |\n",
    "| **gaitset\\_GREW\\.csv**       | GaitSet         | Pre-entrenado en GREW                                     |\n",
    "| **gln\\_phase1.csv**          | GLN (fase 1)    | Primer bloque/fase de extracción del modelo “GLN”         |\n",
    "| **gln\\_phase2.csv**          | GLN (fase 2)    | Fase de refinamiento o bloque final del mismo “GLN”       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Directorio con los CSV\n",
    "data_dir = \"Gait_Embeddings_good/\"\n",
    "\n",
    "# 2. Listar sólo los archivos .csv\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "print(\"Archivos encontrados:\", csv_files)\n",
    "\n",
    "# 3. Leer cada CSV en un DataFrame de pandas\n",
    "dfs = {}\n",
    "for fname in csv_files:\n",
    "    path = os.path.join(data_dir, fname)\n",
    "    dfs[fname] = pd.read_csv(path)\n",
    "\n",
    "# 4. Explorar cada DataFrame\n",
    "for name, df in dfs.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Shape:\", df.shape)                  # filas × columnas\n",
    "    print(\"Columnas:\", df.columns.tolist())    # lista de nombres\n",
    "    print(\"Primeras 5 filas:\")\n",
    "    print(df.head().to_string(index=False))    # muestra las primeras filas\n",
    "\n",
    "    # Opcional: ver tipo de datos y memoria\n",
    "    print(\"\\nInfo:\")\n",
    "    print(df.info())\n",
    "    print(\"\\nDescripción estadística de columnas numéricas:\")\n",
    "    print(df.describe().T)  # transpuesta para leer mejor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f291b9",
   "metadata": {},
   "source": [
    "## Metodología de desarrollo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf249d",
   "metadata": {},
   "source": [
    "1️⃣ datos → 2️⃣ preprocesado y normalización → 3️⃣ split → 4️⃣ Dataset/DataLoader (+ collate) → 5️⃣ modelo → 6️⃣ entrenamiento (función de pérdida y optimizador) → 7️⃣ evaluación → 8️⃣ ajuste → 9️⃣ guardado.\n",
    "\n",
    "- Entender y explorar los datos\n",
    "\n",
    "- Inspecciona las columnas, tipos de variables, balance de clases, valores faltantes y rangos.\n",
    "\n",
    "- Visualiza distribuciones y posibles outliers.\n",
    "\n",
    "- Limpieza y preprocesado\n",
    "\n",
    "- Trata valores faltantes (imputación o eliminación).\n",
    "\n",
    "- Normalización / escalado\n",
    "\n",
    "- Aplica Min–Max o Z-score (standarización) para que todas las características queden en un rango controlado y evites que alguna domine el entrenamiento.\n",
    "\n",
    "- En embeddings, a veces se usa L₂-norm para cada vector si quieres que tengan norma unidad.\n",
    "\n",
    "- Dividir en train / validation / test\n",
    "\n",
    "- Reserva al menos un 10–20 % para test “final”.\n",
    "\n",
    "- Dentro del train crea validación (p. ej. 80/20 o K-fold) para ajustar hiperparámetros sin tocar el test.\n",
    "\n",
    "- Definir Dataset y DataLoader para construir batches\n",
    "\n",
    "- Definir el modelo\n",
    "\n",
    "- Elegir función de pérdida y optimizador\n",
    "\n",
    "- Bucle de entrenamiento\n",
    "\n",
    "- Ajuste de hiperparámetros\n",
    "\n",
    "- Guardado y almacenado de los pesos con torch.save(model.state_dict(), 'modelo.pt').\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aece6ba",
   "metadata": {},
   "source": [
    "### Librerías "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff2c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613b6723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n"
     ]
    },
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n['  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 992, in launch_instance\\n    app.start()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 711, in start\\n    self.io_loop.start()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\tornado\\\\platform\\\\asyncio.py\", line 215, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\asyncio\\\\base_events.py\", line 603, in run_forever\\n    self._run_once()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\asyncio\\\\base_events.py\", line 1906, in _run_once\\n    handle._run()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\asyncio\\\\events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 510, in dispatch_queue\\n    await self.process_one()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 499, in process_one\\n    await dispatch(*args)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 406, in dispatch_shell\\n    await result\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 411, in do_execute\\n    res = shell.run_cell(\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 531, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2945, in run_cell\\n    result = self._run_cell(\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3000, in _run_cell\\n    return runner(coro)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3203, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3382, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3442, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"C:\\\\Users\\\\Acer\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22480\\\\995428710.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\torch\\\\__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\pln\\lib\\site-packages\\torch\\cuda\\__init__.py:260\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[43mqueued_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\pln\\lib\\site-packages\\torch\\cuda\\__init__.py:142\u001b[0m, in \u001b[0;36m_check_capability\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m old_gpu_warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124mFound GPU\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m which is of cuda capability \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124mPyTorch no longer supports this GPU because it is too old.\u001b[39m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124mThe minimum cuda capability supported by this library is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mcuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# on ROCm we don't want this check\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     CUDA_VERSION \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getCompiledVersion()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of GPU: \u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Name: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      4\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing device:\u001b[39m\u001b[38;5;124m'\u001b[39m, DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\pln\\lib\\site-packages\\torch\\cuda\\__init__.py:365\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the name of a device.\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\pln\\lib\\site-packages\\torch\\cuda\\__init__.py:395\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device_properties\u001b[39m(device: _device_t) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    386\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Gets the properties of a device.\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \n\u001b[0;32m    388\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 395\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    396\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Users\\Acer\\anaconda3\\envs\\pln\\lib\\site-packages\\torch\\cuda\\__init__.py:264\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    262\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    263\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call was originally invoked at:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00morig_traceback\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mdelattr\u001b[39m(_tls, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_initializing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n['  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\runpy.py\", line 196, in _run_module_as_main\\n    return _run_code(code, main_globals, None,\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\runpy.py\", line 86, in _run_code\\n    exec(code, run_globals)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel_launcher.py\", line 17, in <module>\\n    app.launch_new_instance()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\traitlets\\\\config\\\\application.py\", line 992, in launch_instance\\n    app.start()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py\", line 711, in start\\n    self.io_loop.start()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\tornado\\\\platform\\\\asyncio.py\", line 215, in start\\n    self.asyncio_loop.run_forever()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\asyncio\\\\base_events.py\", line 603, in run_forever\\n    self._run_once()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\asyncio\\\\base_events.py\", line 1906, in _run_once\\n    handle._run()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\asyncio\\\\events.py\", line 80, in _run\\n    self._context.run(self._callback, *self._args)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 510, in dispatch_queue\\n    await self.process_one()\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 499, in process_one\\n    await dispatch(*args)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 406, in dispatch_shell\\n    await result\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelbase.py\", line 729, in execute_request\\n    reply_content = await reply_content\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\ipkernel.py\", line 411, in do_execute\\n    res = shell.run_cell(\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\ipykernel\\\\zmqshell.py\", line 531, in run_cell\\n    return super().run_cell(*args, **kwargs)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 2945, in run_cell\\n    result = self._run_cell(\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3000, in _run_cell\\n    return runner(coro)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\async_helpers.py\", line 129, in _pseudo_sync_runner\\n    coro.send(None)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3203, in run_cell_async\\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3382, in run_ast_nodes\\n    if await self.run_code(code, result, async_=asy):\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\IPython\\\\core\\\\interactiveshell.py\", line 3442, in run_code\\n    exec(code_obj, self.user_global_ns, self.user_ns)\\n', '  File \"C:\\\\Users\\\\Acer\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_22480\\\\995428710.py\", line 8, in <module>\\n    import torch\\n', '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\torch\\\\__init__.py\", line 1146, in <module>\\n    _C._initExtension(manager_path())\\n', '  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\\n', '  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\\n', '  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\\n', '  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\\n', '  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 197, in <module>\\n    _lazy_call(_check_capability)\\n', '  File \"c:\\\\Users\\\\Acer\\\\anaconda3\\\\envs\\\\pln\\\\lib\\\\site-packages\\\\torch\\\\cuda\\\\__init__.py\", line 195, in _lazy_call\\n    _queued_calls.append((callable, traceback.format_stack()))\\n']"
     ]
    }
   ],
   "source": [
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c02d79",
   "metadata": {},
   "source": [
    "### Guardado de los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5db110",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(model, path: str):\n",
    "    \"\"\"\n",
    "    Guarda en 'path' únicamente los pesos (state_dict) de `model`.\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Modelo guardado en {path}\\n\")\n",
    "\n",
    "\n",
    "def load_model(model_class, path, device=DEVICE, **model_kwargs):\n",
    "    \"\"\"\n",
    "    Carga un modelo de cualquier clase PyTorch definida por el usuario.\n",
    "    \n",
    "    Parámetros:\n",
    "    - model_class: la clase del modelo (MLPClassifier, LSTMClassifier, TransformerClassifier, etc.)\n",
    "    - path:        ruta al archivo .pth con state_dict()\n",
    "    - device:      dispositivo donde cargar el modelo (ej. DEVICE)\n",
    "    - **model_kwargs: argumentos para instanciar la clase de modelo \n",
    "                      (input_dim, hidden_dim, num_layers, ...)\n",
    "    \"\"\"\n",
    "    # Instancia la arquitectura con los kwargs\n",
    "    model = model_class(**model_kwargs).to(device)\n",
    "    # Carga pesos entrenados\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b5b8c0",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------\n",
    "## Modelo MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers=[128, 64], num_classes=3, activation='relu', dropout=0.0,\n",
    "                 bn_layers=(),        # capas (1,2,...) con BatchNorm\n",
    "                 dropout_layers=()    # capas (1,2,...) con Dropout\n",
    "                ):\n",
    "        super().__init__()\n",
    "        activations = {\n",
    "            'relu':    nn.ReLU,\n",
    "            'tanh':    nn.Tanh,\n",
    "            'gelu':    nn.GELU,\n",
    "            'leakyrelu': nn.LeakyReLU,\n",
    "            'elu':     nn.ELU,\n",
    "            'selu':    nn.SELU,\n",
    "        }\n",
    "        act_fn = activations[activation.lower()]\n",
    "        layers, prev_dim = [], input_dim\n",
    "\n",
    "        for idx, h in enumerate(hidden_layers, start=1):\n",
    "            # 1) Capa lineal\n",
    "            layers.append(nn.Linear(prev_dim, h))\n",
    "\n",
    "            # 2) BatchNorm si idx está en bn_layers\n",
    "            if idx in bn_layers:\n",
    "                layers.append(nn.BatchNorm1d(h))\n",
    "\n",
    "            # 3) Activación\n",
    "            layers.append(act_fn())\n",
    "\n",
    "            # 4) Dropout si idx está en dropout_layers\n",
    "            if dropout > 0 and idx in dropout_layers:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "\n",
    "            prev_dim = h\n",
    "\n",
    "        # Capa de salida\n",
    "        layers.append(nn.Linear(prev_dim, num_classes))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004df432",
   "metadata": {},
   "source": [
    "\n",
    "## Preparación de datos, split y bucle de entrenamiento: MLP\n",
    "Al preparar los datos para el MLP, primero agrupamos todas las filas del CSV que pertenecen a un mismo video_ID en una matriz de tamaño (T, D), donde T es el número de frames de ese vídeo y D las 256 características por frame. A continuación aplicamos mean‐pooling o max‐pooling sobre el eje temporal T, colapsando cada matriz a un único vector de dimensión (D,) que resume toda la aproximación del jugador al penalti. Ese conjunto de vectores —uno por vídeo— se divide de forma estratificada en train y test, de modo que en el entrenamiento el DataLoader extrae batches de tamaño fijo (por ejemplo 32) con esos vectores y sus etiquetas, y así el MLP aprende a clasificar la dirección del lanzamiento usando esos resúmenes globales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac3709",
   "metadata": {},
   "source": [
    "PCA (Análisis de Componentes Principales) es un método de reducción de dimensionalidad que dado un conjunto de variables originales, busca un nuevo sistema de variables ortogonales (las “componentes principales”) que capturan la mayor parte de la varianza de los datos. Al proyectar los datos sobre las primeras componentes, se obtiene una representación de menor dimensión que conserva la información más relevante y descarta ruido o redundancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64bfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def prepare_mlp_data(df, pooling, norm, test_size=0.1):\n",
    "    \"\"\"\n",
    "    1) Pooling temporal (mean o max) para cada video_ID -> vector (D,)\n",
    "    2) Split 90/10 estratificado\n",
    "    3) Normalización (MinMax o L2) *solo* con parámetros del train\n",
    "    4) PCA (.fit en train, .transform en train y test)\n",
    "    5) Devolver TensorDatasets para DataLoader\n",
    "    \"\"\"\n",
    "    # 1) Pooling\n",
    "    feat_cols = [c for c in df.columns if c.startswith('feat_')]\n",
    "    seqs, labs = [], []\n",
    "    for vid, grp in df.groupby('video_ID'):\n",
    "        arr = grp[feat_cols].values.astype(np.float32)  # (T, D)\n",
    "        vec = arr.mean(axis=0) if pooling == 'mean' else arr.max(axis=0)\n",
    "        seqs.append(vec)\n",
    "        labs.append(int(grp['shoot_zone'].iloc[0]))\n",
    "    X = np.vstack(seqs)  # (N, D)\n",
    "    y = np.array(labs, dtype=np.int64)\n",
    "\n",
    "    # 2) Split estratificado 90/10\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
    "\n",
    "    # 3) Normalización: FIT en train, TRANSFORM en ambos\n",
    "    if norm == 'minmax':\n",
    "        scaler = MinMaxScaler().fit(X_tr)\n",
    "        X_tr = scaler.transform(X_tr)\n",
    "        X_te = scaler.transform(X_te)\n",
    "    elif norm == 'L2':\n",
    "        # normalize devuelve array numpy\n",
    "        X_tr = normalize(X_tr, norm='l2')\n",
    "        X_te = normalize(X_te, norm='l2')\n",
    "\n",
    "    # 4) PCA 90% de varianza explicada\n",
    "    # if pca_components is None:...REVISAR\n",
    "    pca = PCA(n_components=0.90, random_state=42).fit(X_tr)\n",
    "    X_tr = pca.transform(X_tr)\n",
    "    X_te = pca.transform(X_te)\n",
    "    print(f\"PCA redujo a {pca.n_components_} componentes \"\n",
    "      f\"({pca.explained_variance_ratio_.sum():.2%} varianza explicada)\")\n",
    "\n",
    "    # 5) TensorDatasets\n",
    "    tr_ds = TensorDataset(torch.from_numpy(X_tr).float(), torch.from_numpy(y_tr))\n",
    "    te_ds = TensorDataset(torch.from_numpy(X_te).float(), torch.from_numpy(y_te))\n",
    "    \n",
    "    return tr_ds, te_ds\n",
    "\n",
    "\n",
    "\n",
    "def run_training(model, train_loader, test_loader, epochs, lr, weight_decay):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn   = nn.CrossEntropyLoss()\n",
    "    history   = {'train_loss':[], 'test_acc':[], 'test_f1':[]}\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        # entrenamiento\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb)\n",
    "            loss = loss_fn(out, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "        history['train_loss'].append(total_loss / len(train_loader.dataset))\n",
    "\n",
    "        # evaluación\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in test_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                preds = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(yb.numpy())\n",
    "        all_preds  = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1  = f1_score(all_labels, all_preds, average='macro')\n",
    "        history['test_acc'].append(acc)\n",
    "        history['test_f1'].append(f1)\n",
    "\n",
    "        print(f\"Ep{ep:02d} | loss {history['train_loss'][-1]:.4f} \"\n",
    "              f\"| acc {acc:.4f} | f1_macro {f1:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174f35aa",
   "metadata": {},
   "source": [
    "## Ajuste de Hiperparámetros con Optuna \n",
    "\n",
    "Función que recorre todos los CSV de embeddings en Gait_Embeddings_good, creando por cada uno un estudio independiente que optimiza dinámicamente una FlexibleMLP vía Stratified K-Fold: en cada trial se muestrea pooling (“mean”/“max”), normalización (MinMax/L2), fracción de varianza para PCA, número de capas y sus tamaños, función de activación, tasas de dropout y flags de BatchNorm/Dropout por capa, así como learning rate y weight decay; tras un breve entrenamiento de validación cruzada en PyTorch se calcula el F1 medio de los cinco folds, se guarda el dataframe de trials de cada embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Asegúrate de haber definido FlexibleMLP e importado DEVICE antes de esto.\n",
    "\n",
    "DATA_DIR  = \"Gait_Embeddings_good\"\n",
    "N_TRIALS  = 30\n",
    "N_JOBS    = 4\n",
    "EPOCHS    = 100\n",
    "N_SPLITS  = 5\n",
    "\n",
    "def objective(trial, df):\n",
    "    # 1) Hiperparámetros\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    pooling   = trial.suggest_categorical(\"pooling\", [\"mean\",\"max\"])\n",
    "    norm      = trial.suggest_categorical(\"norm\", [\"minmax\",\"L2\"])\n",
    "    lr        = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3])\n",
    "    wd        = trial.suggest_categorical(\"wd\", [0.0, 1e-6, 1e-5, 1e-4])\n",
    "    n_layers  = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "\n",
    "    base_dim = trial.suggest_categorical(\"base_dim\", [512, 256, 128])\n",
    "    hidden_layers = [ base_dim // (2**i) for i in range(n_layers) ]\n",
    "\n",
    "    activation   = trial.suggest_categorical(\"activation\", [\"relu\",\"tanh\",\"gelu\",\"leakyrelu\",\"elu\",\"selu\"])\n",
    "    dropout_rate = trial.suggest_categorical(\"dropout_rate\", [0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    pca_frac     = trial.suggest_float(\"pca_frac\", 0.7, 0.95, step=0.05)\n",
    "\n",
    "    # BatchNorm y Dropout capa a capa\n",
    "    bn_flags = [trial.suggest_categorical(f\"bn_{i}\", [False, True]) for i in range(1, n_layers+1)]\n",
    "    do_flags = [trial.suggest_categorical(f\"do_{i}\", [False, True]) for i in range(1, n_layers+1)]\n",
    "    \n",
    "    bn_layers      = [i for i,f in enumerate(bn_flags, start=1) if f]\n",
    "    dropout_layers = [i for i,f in enumerate(do_flags, start=1) if f]\n",
    "\n",
    "    # 2) Preparar X, y\n",
    "    feat_cols = [c for c in df.columns if c.startswith(\"feat_\")]\n",
    "    X, y = [], []\n",
    "    for vid, grp in df.groupby(\"video_ID\"):\n",
    "        arr = grp[feat_cols].values.astype(np.float32)\n",
    "        vec = arr.mean(axis=0) if pooling==\"mean\" else arr.max(axis=0)\n",
    "        X.append(vec);  y.append(int(grp[\"shoot_zone\"].iloc[0]))\n",
    "    X = np.stack(X);  y = np.array(y)\n",
    "\n",
    "    # 3) Stratified K-Fold\n",
    "    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(X, y):\n",
    "        X_tr, X_va = X[tr_idx], X[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "        # 4) Normalización\n",
    "        if norm==\"minmax\":\n",
    "            scaler = MinMaxScaler().fit(X_tr)\n",
    "            X_tr = scaler.transform(X_tr)\n",
    "            X_va = scaler.transform(X_va)\n",
    "        elif norm==\"L2\":\n",
    "            X_tr = normalize(X_tr, norm=\"l2\")\n",
    "            X_va = normalize(X_va, norm=\"l2\")\n",
    "\n",
    "        # 5) PCA\n",
    "        pca = PCA(n_components=pca_frac, random_state=42).fit(X_tr)\n",
    "        X_tr = pca.transform(X_tr)\n",
    "        X_va = pca.transform(X_va)\n",
    "\n",
    "        # 6) DataLoaders\n",
    "        tr_ds = TensorDataset(torch.from_numpy(X_tr).float(),\n",
    "                              torch.from_numpy(y_tr))\n",
    "        va_ds = TensorDataset(torch.from_numpy(X_va).float(),\n",
    "                              torch.from_numpy(y_va))\n",
    "        tr_ld = DataLoader(tr_ds, batch_size=batch_size, shuffle=True)\n",
    "        va_ld = DataLoader(va_ds, batch_size=batch_size)\n",
    "\n",
    "        # 7) Modelo FlexibleMLP\n",
    "        model = FlexibleMLP(\n",
    "            input_dim=X_tr.shape[1],\n",
    "            hidden_layers=hidden_layers,\n",
    "            activation=activation,\n",
    "            dropout=dropout_rate,\n",
    "            bn_layers=bn_layers,\n",
    "            dropout_layers=dropout_layers\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # 8) Entrenamiento breve\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        loss_fn   = nn.CrossEntropyLoss()\n",
    "        for _ in range(EPOCHS):\n",
    "            model.train()\n",
    "            for xb, yb in tr_ld:\n",
    "                xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                loss_fn(model(xb), yb).backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # 9) Evaluación F1\n",
    "        model.eval()\n",
    "        preds, labs = [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in va_ld:\n",
    "                xb = xb.to(DEVICE)\n",
    "                p = model(xb).argmax(dim=1).cpu().numpy()\n",
    "                preds.append(p);  labs.append(yb.numpy())\n",
    "        preds = np.concatenate(preds)\n",
    "        labs  = np.concatenate(labs)\n",
    "        fold_scores.append(f1_score(labs, preds, average=\"macro\"))\n",
    "\n",
    "    return float(np.mean(fold_scores))\n",
    "\n",
    "\n",
    "def optimize_embeddings():\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    summary = []\n",
    "\n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        if not fname.endswith(\".csv\"):\n",
    "            continue\n",
    "        print(f\"\\n=== Optimizing {fname} ===\")\n",
    "        df = pd.read_csv(os.path.join(DATA_DIR, fname))\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(\n",
    "            lambda t: objective(t, df),\n",
    "            n_trials=N_TRIALS,\n",
    "            n_jobs=N_JOBS,\n",
    "            timeout=3600\n",
    "        )\n",
    "\n",
    "        print(f\"→ Best F1 for {fname}: {study.best_value:.4f}\")\n",
    "        print(\"  Params:\", study.best_params)\n",
    "\n",
    "        study.trials_dataframe().to_csv(f\"results/best_parameters/MLP_Optuna_{fname}.csv\", index=False)\n",
    "        summary.append({\n",
    "            \"embedding\": fname,\n",
    "            \"best_f1\": study.best_value,\n",
    "            **study.best_params\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(summary).to_csv(\"results/MLP/best_parameters/best_params_MLP.csv\", index=False)\n",
    "    print(\"\\nSummary saved to results/MLP_optuna_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20017283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna para todos los embeddings\n",
    "optimize_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4b152",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d20515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "DATA_DIR = \"Gait_Embeddings_good\"\n",
    "POOLS    = ['mean', 'max']\n",
    "NORMS    = ['minmax', 'L2']\n",
    "EPOCHS   = 500\n",
    "BATCH    = 32\n",
    "LOAD_MODEL = False  # Si True, carga un modelo preentrenado en lugar de entrenar uno nuevo\n",
    "LR = 1e-3   # learning_rate\n",
    "WD = 1e-4   # weight_decay\n",
    "\n",
    "\n",
    "PATH = \"saved_models/MLP/\"\n",
    "os.makedirs(PATH, exist_ok=True)\n",
    "THRESHOLD = 0.5  # Umbral para guardar modelos\n",
    "\n",
    "results = []\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    if not fname.endswith('.csv'):\n",
    "        continue\n",
    "    print(f\"\\n--- Entrenando MLP con {fname} ---\")\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, fname))\n",
    "\n",
    "    for pool in POOLS:\n",
    "        for norm in NORMS:\n",
    "            tr_ds, te_ds = prepare_mlp_data(df, pooling=pool, norm=norm, test_size=0.2)\n",
    "            tr_loader = DataLoader(tr_ds, batch_size=BATCH, shuffle=True)\n",
    "            te_loader = DataLoader(te_ds, batch_size=BATCH)\n",
    "\n",
    "            model = MLPClassifier(tr_ds[0][0].shape[0]).to(DEVICE) \n",
    "            \n",
    "            # Si LOAD_MODEL es True, intenta cargar un modelo preentrenado\n",
    "            if LOAD_MODEL == True:\n",
    "                model_path = os.path.join(PATH, f\"mlp_{pool}_{norm}_{fname.replace('.csv', '')}.pth\")\n",
    "                if os.path.exists(model_path):\n",
    "                    print(f\"Cargando modelo preentrenado desde {model_path}\")\n",
    "                    model = load_model(MLPClassifier, model_path, input_dim=tr_ds[0][0].shape[0])\n",
    "            \n",
    "            history = run_training(model, tr_loader, te_loader, epochs=EPOCHS, lr=LR, weight_decay=WD)\n",
    "\n",
    "            results.append({\n",
    "                'extractor':     fname,\n",
    "                'model':         'MLP',\n",
    "                'epochs':        EPOCHS,\n",
    "                'batch_size':    BATCH,\n",
    "                'input_dim':     tr_ds[0][0].shape[0],\n",
    "                'pooling':       pool,\n",
    "                'normalization': norm,\n",
    "                'learning_rate': LR,\n",
    "                'weight_decay':  WD,\n",
    "                'train_loss':   round(history['train_loss'][-1], 5),\n",
    "                'accuracy':      round(history['test_acc'][-1], 5),\n",
    "                'f1_macro':      round(history['test_f1'][-1], 5)\n",
    "            })\n",
    "            \n",
    "            \n",
    "            # Guardar modelo si la precisión supera el umbral #REVISAR\n",
    "            if history['test_acc'][-1] > THRESHOLD:\n",
    "                print(f\"Guardando modelo con acc {history['test_acc'][-1]:.4f} > {THRESHOLD}\")\n",
    "                \n",
    "                model_path = os.path.join(PATH, f\"mlp_{pool}_{norm}_{fname.replace('.csv', '')}.pth\")\n",
    "                save_model(model, model_path)\n",
    "            \n",
    "            \n",
    "\n",
    "# Guardar resultados finales\n",
    "df_results = pd.DataFrame(results)\n",
    "results_path = \"results/MLP/mlp_results.csv\"\n",
    "\n",
    "# Si el archivo existe, añadir los nuevos resultados al final\n",
    "if os.path.exists(results_path):\n",
    "    df_existing = pd.read_csv(results_path)\n",
    "    \n",
    "    with open(results_path, 'a', newline='') as f:\n",
    "        f.write(\"\\n\") # Añadir una fila vacía para separar los resultados\n",
    "\n",
    "    df_results.to_csv(results_path, mode='a', header=False, index=False)\n",
    "\n",
    "    print(f\"\\n Resultados MLP añadidos a {results_path}\")\n",
    "else:\n",
    "    # Si no existe, crear nuevo archivo\n",
    "    df_results.to_csv(results_path, index=False)\n",
    "    print(f\"\\n Nuevo archivo de resultados LSTM creado en {results_path}\")\n",
    "\n",
    "print(\"\\n Resultados guardados en mlp_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc74d1",
   "metadata": {},
   "source": [
    "## Matriz de Confusión y Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e41a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_confusion_matrix(model, dataloader, device, class_names):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Adaptar según tu DataLoader (2 ó 3 elementos)\n",
    "            if len(batch) == 3:\n",
    "                xb, lengths, yb = batch\n",
    "                xb, lengths = xb.to(device), lengths.to(device)\n",
    "                logits = model(xb, lengths)\n",
    "            else:\n",
    "                xb, yb = batch\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(yb.numpy())\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Dibujar\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Matriz de Confusión\")\n",
    "    plt.colorbar()\n",
    "    ticks = np.arange(len(class_names))\n",
    "    plt.xticks(ticks, class_names, rotation=45)\n",
    "    plt.yticks(ticks, class_names)\n",
    "    thresh = cm.max() / 2\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                     ha=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.ylabel(\"Etiqueta real\")\n",
    "    plt.xlabel(\"Etiqueta predicha\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return cm\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_multiclass_roc(model, dataloader, device, class_names):\n",
    "    model.eval()\n",
    "    y_true, y_score = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            if len(batch) == 3:\n",
    "                xb, lengths, yb = batch\n",
    "                xb, lengths = xb.to(device), lengths.to(device)\n",
    "                logits = model(xb, lengths)\n",
    "            else:\n",
    "                xb, yb = batch\n",
    "                xb = xb.to(device)\n",
    "                logits = model(xb)\n",
    "\n",
    "            probs = F.softmax(logits, dim=1).cpu().numpy()\n",
    "            y_score.append(probs)\n",
    "            y_true.append(yb.numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_score = np.concatenate(y_score)\n",
    "    n_classes = y_score.shape[1]\n",
    "    y_true_bin = label_binarize(y_true, classes=list(range(n_classes)))\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_score[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC={roc_auc:.2f})\")\n",
    "\n",
    "    plt.plot([0,1], [0,1], 'k--', label=\"Azar\")\n",
    "    plt.xlabel(\"Tasa Falsos Positivos\")\n",
    "    plt.ylabel(\"Tasa Verdaderos Positivos\")\n",
    "    plt.title(\"ROC Multi-clase (One-vs-Rest)\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d953ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes un modelo entrenado y un DataLoader de test\n",
    "class_names = ['derecha', 'centro', 'izquierda']\n",
    "evaluate_multiclass_roc(model, te_loader, DEVICE, class_names)\n",
    "cm = evaluate_confusion_matrix(model, te_loader, DEVICE, class_names)\n",
    "\n",
    "# Numero de aciertos y errores\n",
    "print(\"\\n=== Resultados de la matriz de confusión para test ===\")\n",
    "print(\"Aciertos (diagonal):\", np.diag(cm).sum())\n",
    "print(\"Errores (fuera de la diagonal):\", cm.sum() - np.diag(cm).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3552f477",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "## Modelo LSTM y BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea37ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,      # 256 features del CSV\n",
    "        hidden_dim,     # Dimensión oculta de la LSTM \n",
    "        num_layers,     # Número de capas LSTM \n",
    "        bidirectional,  # Si usar BiLSTM\n",
    "        dropout        # Dropout entre capas y antes de clasificación\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Capas LSTM apiladas con dropout entre ellas\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout if num_layers > 1 else 0.0  # Dropout solo si hay múltiples capas\n",
    "        )\n",
    "        \n",
    "        # 2. Dimensiones de salida\n",
    "        self.lstm_out_dim = hidden_dim * (2 if bidirectional else 1)  # Dimensión de salida LSTM\n",
    "        self.hidden_dim = self.lstm_out_dim // 2 if bidirectional else self.lstm_out_dim\n",
    "\n",
    "        # 3. Capa densa final\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.lstm_out_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, 3)  # 3 clases: derecha, centro, izquierda\n",
    "        )\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # 1. Empaquetar secuencias variables\n",
    "        packed = pack_padded_sequence(x, lengths.cpu(), \n",
    "                                    batch_first=True, \n",
    "                                    enforce_sorted=False)\n",
    "\n",
    "        # 2. Procesar con LSTM\n",
    "        # Shape de h_n: (num_layers * 2, batch_size, hidden_dim) el caso de BiLSTM\n",
    "        # el num_layers * 2 es porque hay una capa forward y otra backward de ahí el 2\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        \n",
    "        # 3. Obtener estado final (último estado de la última capa)\n",
    "        if self.lstm.bidirectional:\n",
    "            h_forward = h_n[-2]  # última capa forward\n",
    "            h_backward = h_n[-1]  # última capa backward\n",
    "            h_final = torch.cat([h_forward, h_backward], dim=1)\n",
    "        else:\n",
    "            h_final = h_n[-1]\n",
    "\n",
    "        # 4. Pasar por la capa densa final\n",
    "        return self.fc(h_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc2d0d",
   "metadata": {},
   "source": [
    "\n",
    "## Preparación de datos, split y bucle de entrenamiento: LSTM\n",
    "\n",
    "**Normalización**: antes de la partición train/test se aplican dos esquemas alternativos de escalado MinMax (entrenando un MinMaxScaler sobre todos los frames y transformando cada secuencia) o L2-norm (normalizando cada frame por su norma L2) para unificar la escala de las características. Función: **`prepare_seq_data`**\n",
    "\n",
    "**DataLoader con función `collate_sequences`**: cada lote de secuencias de longitud variable se rellena (pad) al tamaño de la más larga y se devuelve un tensor de longitudes, lo que permite a la LSTM procesar correctamente secuencias de distinta longitud en un mismo batch.\n",
    "\n",
    "**Optimización con Adam, weight decay y grad-clip**: se entrena con Adam, añadiendo regularización L2 (weight_decay) y aplicando clip_grad_norm_ tras el backward para limitar la magnitud de los gradientes y prevenir explosiones que se manifiestan como picos abruptos en la train_loss. Función: **`run_training_lstm`**\n",
    "\n",
    "**Early stopping**: tras 300 épocas sin una reducción significativa de la train_loss (más allá de un umbral min_delta), el entrenamiento se detiene para evitar sobreajuste y ahorro de recursos computacionales. `''`\n",
    "\n",
    "**Seguimiento del mejor F1 con “warm-up”**: el cómputo de best_f1_score comienza únicamente a partir de la época 100. Esto impide registrar picos de F1 obtenidos por azar en fases iniciales, cuando el train_loss sigue siendo alto y el modelo aún no ha aprendido de forma estable. Establecer este mínimo de 100 épocas asegura que las mejoras de F1 reflejen un aprendizaje consolidado y verdaderamente generalizable. `''`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ec41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_sequences(batch):\n",
    "    \"\"\"\n",
    "    Recibe una lista de (tensor_seq, label).\n",
    "    Devuelve:\n",
    "      - padded: tensor (B, T_max, D)\n",
    "      - lengths: tensor (B,)\n",
    "      - labels: tensor (B,)\n",
    "    \"\"\"\n",
    "    seqs, labels = zip(*batch)\n",
    "    lengths = torch.tensor([s.size(0) for s in seqs], dtype=torch.long)\n",
    "    padded = pad_sequence(seqs, batch_first=True)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return padded, lengths, labels\n",
    "\n",
    "def prepare_seq_data(df, norm, test_size):\n",
    "    \"\"\"\n",
    "    df: DataFrame con columnas feat_0…feat_D-1, video_ID y shoot_zone\n",
    "    norm: 'minmax' o 'l2'\n",
    "    Devuelve dos listas de muestras (tensor_seq, label) para train y test.\n",
    "    \"\"\"\n",
    "    # 1) Extraer todas las secuencias y etiquetas\n",
    "    feat_cols = [c for c in df.columns if c.startswith('feat_')]\n",
    "    seqs, labs = [], []\n",
    "    for vid, grp in df.groupby('video_ID'):\n",
    "        arr = grp[feat_cols].values.astype(np.float32)  # (T, D)\n",
    "        seqs.append(arr)\n",
    "        labs.append(int(grp['shoot_zone'].iloc[0]))\n",
    "\n",
    "    # 2) Normalizar\n",
    "    if norm == 'minmax':\n",
    "        all_frames = np.vstack(seqs)\n",
    "        scaler = MinMaxScaler().fit(all_frames)\n",
    "        seqs = [scaler.transform(s) for s in seqs]\n",
    "    elif norm == 'L2':\n",
    "        seqs = [normalize(s, norm='l2', axis=1) for s in seqs]\n",
    "\n",
    "    # 3) Split estratificado\n",
    "    idx = list(range(len(seqs)))\n",
    "    idx_tr, idx_te = train_test_split(idx, test_size=test_size, stratify=labs, random_state=16)\n",
    "\n",
    "    # 4) Convertir a listas de tuplas (tensor_seq, label)\n",
    "    train_list = [(torch.from_numpy(seqs[i]), labs[i]) for i in idx_tr]\n",
    "    test_list  = [(torch.from_numpy(seqs[i]), labs[i]) for i in idx_te]\n",
    "\n",
    "\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "def run_training_lstm(model, train_loader, test_loader, epochs, lr, wd, min_epochs):\n",
    "    \"\"\"\n",
    "    Función de entrenamiento específica para el modelo LSTM\n",
    "    Args:\n",
    "        model: Instancia de LSTMClassifier\n",
    "        train_loader: DataLoader con datos de entrenamiento (incluye lengths)\n",
    "        test_loader: DataLoader con datos de test (incluye lengths)\n",
    "        epochs: Número de épocas de entrenamiento\n",
    "        lr: Learning rate para el optimizador\n",
    "    Returns:\n",
    "        history: Diccionario con métricas de entrenamiento\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    history = {'train_loss': [],'test_loss':[], 'test_acc': [], 'test_f1': []}\n",
    "\n",
    "    patience = 50  # Paciencia para early stopping\n",
    "    min_delta = 0.0001  # Mínima mejora para considerar que hay progreso\n",
    "    best_loss = float('inf')  # Mejor pérdida inicial\n",
    "    epochs_no_improve = 0  # Contador de épocas sin mejora\n",
    "\n",
    "    best_f1_score = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        # --- TRAIN ---\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, lengths, yb in train_loader:\n",
    "            # Mover datos a GPU/CPU\n",
    "            xb = xb.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            yb = yb.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb, lengths)\n",
    "            loss = loss_fn(out, yb)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Clipping de gradientes para evitar explosiones\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(avg_loss)\n",
    "\n",
    "        # --- TEST ---\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        #test_sum = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for xb, lengths, yb in test_loader:\n",
    "                xb = xb.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                \n",
    "                # Predicción\n",
    "                outputs = model(xb, lengths)\n",
    "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                \n",
    "                #test_sum += loss_fn(outputs, yb).item() * yb.size(0)\n",
    "                \n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(yb.numpy())\n",
    "\n",
    "        # Calcular métricas\n",
    "        #avg_test_loss = test_sum / len(test_loader.dataset)\n",
    "        #history['test_loss'].append(avg_test_loss)\n",
    "\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        history['test_acc'].append(acc)\n",
    "        history['test_f1'].append(f1)\n",
    "\n",
    "        # Imprimir progreso\n",
    "        print(f\"Época {ep:02d}/{epochs} | \"\n",
    "              f\"train_loss {avg_loss:.4f} | \"\n",
    "              f\"accuracy {acc:.4f} | \"\n",
    "              f\"f1_macro {f1:.4f}\")\n",
    "        \n",
    "        # trackear best F1 solo tras un mínimo de épocas\n",
    "        if ep > (min_epochs / 2) and f1 > best_f1_score + 1e-5:\n",
    "            best_f1_score = f1\n",
    "            best_epoch = ep\n",
    "\n",
    "        # — Early stopping basado en train_loss — o se puede hacer para test_loss\n",
    "        if ep > min_epochs:\n",
    "            if avg_loss < best_loss - min_delta:\n",
    "                best_loss = avg_loss\n",
    "                epochs_no_improve = 0\n",
    "            else:\n",
    "                epochs_no_improve += 1\n",
    "            \n",
    "            if avg_loss < 0.001:  # Si la pérdida es muy baja, detener\n",
    "                print(f\"\\nEarly stopping tras {ep} épocas con train_loss={avg_loss:.4f}.\")\n",
    "                break\n",
    "\n",
    "            if epochs_no_improve >= patience and avg_loss < 0.01: \n",
    "                print(f\"\\nEarly stopping tras {epochs_no_improve} épocas \"\n",
    "                      f\"sin mejorar el train_loss (delta<{min_delta}).\")\n",
    "                break\n",
    "\n",
    "    return history, ep, best_f1_score, best_epoch\n",
    "\n",
    "# REVISAR: en vez de devolver ep y best_f1_score, devolver un diccionario con todo dentro de history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268058bf",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros\n",
    "\n",
    "Se emplea StratifiedKFold sobre los IDs de vídeo (video_ID), no sobre los fotogramas individuales, para crear 5 particiones que mantienen la proporción de clases en cada fold. Para cada partición, se extraen dos listas de vídeos: una de entrenamiento y otra de validación, y se filtra el DataFrame original para incluir únicamente las secuencias completas de esos vídeos. Cada secuencia se normaliza (MinMax o L2) y se empaqueta en un DataLoader con collate_sequences, garantizando que ningún vídeo se mezcle entre train/val y preservando su continuidad temporal. Así se evita la fuga de información entre folds y se evalúa el modelo sobre vídeos inéditos en cada ronda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuración global\n",
    "DATA_DIR = \"Gait_Embeddings_good\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def objective(trial, df):\n",
    "    \"\"\"Función objetivo para Optuna\"\"\"\n",
    "    config = {\n",
    "        'hidden_dim': trial.suggest_categorical(\"hidden_dim\", [64, 128, 256, 512]),\n",
    "        'num_layers': trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        'bidirectional': trial.suggest_categorical(\"bidirectional\", [False, True]),\n",
    "        'dropout': trial.suggest_categorical(\"dropout\", [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]),\n",
    "        'lr': trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3]),\n",
    "        'batch_size': trial.suggest_categorical(\"batch_size\", [32, 64, 128]),\n",
    "        'norm': trial.suggest_categorical(\"norm\", [\"minmax\", \"L2\"])\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Trial {trial.number}\")\n",
    "    print(f\"Configuración: {config}\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "\n",
    "    # Preparar datos para K-Fold\n",
    "    video_ids = list(df.groupby('video_ID').groups.keys())\n",
    "    labels = [int(df[df['video_ID']==vid]['shoot_zone'].iloc[0]) for vid in video_ids]\n",
    "\n",
    "    # K-Fold Cross Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=16)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(video_ids, labels)):\n",
    "        print(f\"\\nFold {fold+1}/5\")\n",
    "        \n",
    "        # Separar datos de train/val\n",
    "        train_ids = [video_ids[i] for i in train_idx]\n",
    "        val_ids = [video_ids[i] for i in val_idx]\n",
    "        \n",
    "        df_train = df[df['video_ID'].isin(train_ids)]\n",
    "        df_val = df[df['video_ID'].isin(val_ids)]\n",
    "        \n",
    "        # Preparar datos\n",
    "        feat_cols = [c for c in df_train.columns if c.startswith('feat_')]\n",
    "        \n",
    "        # Train data\n",
    "        train_seqs = []\n",
    "        train_labs = []\n",
    "        for vid, grp in df_train.groupby('video_ID'):\n",
    "            arr = grp[feat_cols].values.astype(np.float32)\n",
    "            if config['norm'] == 'minmax':\n",
    "                arr = MinMaxScaler().fit_transform(arr)\n",
    "            elif config['norm'] == 'L2':  \n",
    "                arr = normalize(arr, norm='l2', axis=1)\n",
    "            train_seqs.append(torch.from_numpy(arr))\n",
    "            train_labs.append(int(grp['shoot_zone'].iloc[0]))\n",
    "        \n",
    "        # Val data\n",
    "        val_seqs = []\n",
    "        val_labs = []\n",
    "        for vid, grp in df_val.groupby('video_ID'):\n",
    "            arr = grp[feat_cols].values.astype(np.float32)\n",
    "            if config['norm'] == 'minmax':\n",
    "                arr = MinMaxScaler().fit_transform(arr)\n",
    "            else:  # L2\n",
    "                arr = normalize(arr, norm='l2', axis=1)\n",
    "            val_seqs.append(torch.from_numpy(arr))\n",
    "            val_labs.append(int(grp['shoot_zone'].iloc[0]))\n",
    "\n",
    "        # Crear datasets y dataloaders\n",
    "        train_data = list(zip(train_seqs, train_labs))\n",
    "        val_data = list(zip(val_seqs, val_labs))\n",
    "        \n",
    "        train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True, collate_fn=collate_sequences)\n",
    "        val_loader = DataLoader(val_data, batch_size=config['batch_size'], shuffle=False, collate_fn=collate_sequences)\n",
    "\n",
    "        # Crear y entrenar modelo\n",
    "        model = LSTMClassifier(\n",
    "            input_dim=df.filter(like='feat_').shape[1],\n",
    "            hidden_dim=config['hidden_dim'],\n",
    "            num_layers=config['num_layers'],\n",
    "            bidirectional=config['bidirectional'],\n",
    "            dropout=config['dropout']\n",
    "        ).to(DEVICE)\n",
    "\n",
    "        # Entrenar\n",
    "        history, _, _, _ = run_training_lstm(\n",
    "            model=model,\n",
    "            train_loader=train_loader, \n",
    "            test_loader=val_loader,\n",
    "            epochs=200,  \n",
    "            lr=config['lr'],\n",
    "            wd=0, # No usamos weight decay aquí\n",
    "            min_epochs=100 # para early stopping\n",
    "\n",
    "        )\n",
    "        \n",
    "        # Guardar mejor F1 score del fold\n",
    "        fold_scores.append(max(history['test_f1']))\n",
    "\n",
    "    mean_f1 = np.mean(fold_scores)\n",
    "    print(f\"\\nConfiguración: {config}\")\n",
    "    print(f\"F1-score medio: {mean_f1:.4f}\")\n",
    "    \n",
    "    return mean_f1\n",
    "\n",
    "\n",
    "\n",
    "def optimize_embeddings():\n",
    "    \"\"\"Ejecuta optimización para cada embedding base\"\"\"\n",
    "    \n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    results = {}\n",
    "    \n",
    "    for fname in os.listdir(DATA_DIR):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Optimizando {fname}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Cargar datos\n",
    "        df = pd.read_csv(os.path.join(DATA_DIR, fname))\n",
    "        \n",
    "        # Crear y ejecutar estudio\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(\n",
    "            lambda trial: objective(trial, df),\n",
    "            n_trials=20,  # 30 trials por embedding\n",
    "            n_jobs=10,     # Paralelización\n",
    "            timeout=3600  # Timeout de 1 hora por embedding\n",
    "        )\n",
    "        \n",
    "        # Guardar resultados\n",
    "        results[fname] = {\n",
    "            'best_params': study.best_params,\n",
    "            'best_f1': study.best_value\n",
    "        }\n",
    "        \n",
    "        # Guardar trials en CSV\n",
    "        study_df = study.trials_dataframe()\n",
    "        study_df.to_csv(f\"results/LSTM_hyperparams_{fname}.csv\", index=False)\n",
    "        \n",
    "        print(f\"\\nMejores parámetros para {fname}:\")\n",
    "        print(f\"F1-score: {study.best_value:.4f}\")\n",
    "        print(\"Configuración:\", study.best_params)\n",
    "        \n",
    "    # Guardar resumen final\n",
    "    final_results = []\n",
    "    for embedding, res in results.items():\n",
    "        row = {\n",
    "            'embedding': embedding,\n",
    "            'best_f1': res['best_f1'],\n",
    "            **res['best_params']\n",
    "        }\n",
    "        final_results.append(row)\n",
    "    \n",
    "    df_final = pd.DataFrame(final_results)\n",
    "    df_final.to_csv(\"results/best_parameters/best_params_LSTM.csv\", index=False)\n",
    "    print(\"\\nResumen final guardado en results/best/parameters/best_params_LSTM.csv\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e531ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna\n",
    "results = optimize_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a897a0",
   "metadata": {},
   "source": [
    "## Entrenamiento \n",
    "Configuración de hiperparámetros a partir de los resultados obtenidos mediante Optuna.\n",
    "- Mencionar que las métricas que se añaden a los resultados obtenidos son las siguientes:\n",
    "- f1-score...\n",
    "\n",
    "Usando clip_grad_norm tampoco se obtenia apenas diferencia en los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24265cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuración \n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIR = \"Gait_Embeddings_good\"\n",
    "EPOCHS = 1500\n",
    "BATCH = 32\n",
    "LR = 1e-3\n",
    "WD = 0.0\n",
    "NORM = 'L2'\n",
    "F1_THRESHOLD = 0.5  # Umbral mínimo de F1 para considerar un modelo válido\n",
    "LOAD_MODEL = False  # Si True, carga un modelo preentrenado en lugar de entrenar uno nuevo\n",
    "\n",
    "\n",
    "# Hiperparámetros de LSTM\n",
    "num_layers    = 1\n",
    "hidden_dim    = 512\n",
    "bidirectional = True\n",
    "dropout       = 0.0\n",
    "\n",
    "\n",
    "results_lstm = []\n",
    "\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    if not fname.endswith('.csv'):\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n--- Entrenando LSTM con {fname} ---\")\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, fname))\n",
    "    \n",
    "    # Preparar datos\n",
    "    train_list, test_list = prepare_seq_data(df, norm=NORM, test_size=0.2)\n",
    "    tr_loader = DataLoader(train_list, batch_size=BATCH, shuffle=True, collate_fn=collate_sequences)\n",
    "    te_loader = DataLoader(test_list, batch_size=BATCH, shuffle=False, collate_fn=collate_sequences)\n",
    "\n",
    "    # Crear y entrenar modelo\n",
    "    model = LSTMClassifier(\n",
    "        input_dim=df.filter(like='feat_').shape[1],\n",
    "        hidden_dim=hidden_dim,\n",
    "        num_layers=num_layers,\n",
    "        bidirectional=bidirectional,\n",
    "        dropout=dropout\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    # REVISAR EL MEOTDO DE CARGA DEL MODELO NO VA BIEN\n",
    "    # Si LOAD_MODEL es True, intenta cargar un modelo preentrenado\n",
    "    if LOAD_MODEL:\n",
    "        model_path = os.path.join(\"saved_models/LSTM\", f\"lstm_{NORM}_hidden{hidden_dim}_layers{num_layers}_batch{BATCH}_LR{LR}_dropout{dropout}_BiLSTM_{bidirectional}_{fname.replace('.csv', '')}.pth\")\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Cargando modelo preentrenado desde {model_path}\")\n",
    "            model = load_model(LSTMClassifier, model_path, input_dim=df.filter(like='feat_').shape[1])\n",
    "\n",
    "    history, ep, best_f1, best_epoch = run_training_lstm(model, tr_loader, te_loader, epochs=EPOCHS, lr=LR, wd=WD, min_epochs=100) \n",
    "\n",
    "\n",
    "    # Guardar resultados\n",
    "    results_lstm.append({\n",
    "        'extractor': fname,\n",
    "        'model': 'LSTM',\n",
    "        'epochs': int(ep),\n",
    "        'batch_size': int(BATCH),\n",
    "        'normalization': NORM,\n",
    "        'num_layers': int(num_layers),\n",
    "        'hidden_dim': int(hidden_dim),\n",
    "        'bidirectional': bidirectional,\n",
    "        'dropout': dropout,\n",
    "        'lr': LR,\n",
    "        'train_loss': round(history['train_loss'][-1], 5),\n",
    "        'accuracy': round(history['test_acc'][-1], 5),\n",
    "        'f1_macro': round(history['test_f1'][-1], 5),\n",
    "        \n",
    "        'best_f1_score': round(best_f1, 5),\n",
    "        'best_epoch': best_epoch\n",
    "    })\n",
    "\n",
    "    if best_f1 < F1_THRESHOLD:\n",
    "        print(f\"\\nModelo con F1 {best_f1:.4f} por debajo del umbral {F1_THRESHOLD}. No se guardará.\")\n",
    "        continue\n",
    "\n",
    "    # Guardar modelo\n",
    "    model_path = os.path.join(\"saved_models/LSTM\", f\"lstm_{NORM}_hidden{hidden_dim}_layers{num_layers}_batch{BATCH}_LR{LR}_dropout{dropout}_BiLSTM_{bidirectional}_{fname.replace('.csv', '')}.pth\")\n",
    "    save_model(model, model_path)\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results_lstm)\n",
    "results_path = \"results/LSTM/lstm_results.csv\"\n",
    "\n",
    "# Si el archivo existe, añadir los nuevos resultados al final\n",
    "if os.path.exists(results_path):\n",
    "    dtype_dict = {\n",
    "        'epochs': 'Int64',\n",
    "        'batch_size': 'Int64',\n",
    "        'num_layers': 'Int64',\n",
    "        'hidden_dim': 'Int64',\n",
    "        'best_epoch': 'Int64'\n",
    "    }\n",
    "    df_existing = pd.read_csv(results_path, dtype=dtype_dict)\n",
    "    \n",
    "    with open(results_path, 'a', newline='') as f:\n",
    "        f.write(\"\\n\") # Añadir una fila vacía para separar los resultados\n",
    "\n",
    "    df_results.to_csv(results_path, mode='a', header=False, index=False)\n",
    "\n",
    "    print(f\"\\n Resultados LSTM añadidos a {results_path}\")\n",
    "else:\n",
    "    # Si no existe, crear nuevo archivo\n",
    "    df_results.to_csv(results_path, index=False)\n",
    "    print(f\"\\n Nuevo archivo de resultados LSTM creado en {results_path}\")\n",
    "\n",
    "# Mostrar todos los resultados\n",
    "print(\"\\nResumen de todos los resultados:\")\n",
    "print(pd.read_csv(results_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdef3c03",
   "metadata": {},
   "source": [
    "## Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cde770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asumiendo que ya tienes un modelo entrenado y un DataLoader de test\n",
    "class_names = ['derecha', 'centro', 'izquierda']\n",
    "evaluate_multiclass_roc(model, te_loader, DEVICE, class_names)\n",
    "cm = evaluate_confusion_matrix(model, te_loader, DEVICE, class_names)\n",
    "\n",
    "# Numero de aciertos y errores\n",
    "print(\"\\n=== Resultados de la matriz de confusión para test ===\")\n",
    "print(\"Aciertos (diagonal):\", np.diag(cm).sum())\n",
    "print(\"Errores (fuera de la diagonal):\", cm.sum() - np.diag(cm).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3f4a2",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "## Modelo TCN - Temporal Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"Elimina el exceso de padding al final de la secuencia.\"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x tiene forma (batch, channels, seq_len + 2*(kernel_size-1)*dilation)\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"Bloque residual de la TCN.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(in_channels, out_channels,\n",
    "                                           kernel_size,\n",
    "                                           stride=stride,\n",
    "                                           padding=padding,\n",
    "                                           dilation=dilation))\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(out_channels, out_channels,\n",
    "                                           kernel_size,\n",
    "                                           stride=stride,\n",
    "                                           padding=padding,\n",
    "                                           dilation=dilation))\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Si cambia el número de canales, ajustamos la rama de shortcut\n",
    "        self.downsample = (nn.Conv1d(in_channels, out_channels, 1)\n",
    "                           if in_channels != out_channels else None)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.chomp1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.drop1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.chomp2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.drop2(out)\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    \"\"\"Stack de bloques temporales con dilataciones crecientes.\"\"\"\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=3, dropout=0.2):\n",
    "        \"\"\"\n",
    "        num_inputs: dimensión de entrada (features)\n",
    "        num_channels: lista con número de filtros por capa, p.ej. [128, 128, 128]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            in_ch = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_ch = num_channels[i]\n",
    "            dilation = 2 ** i\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            layers += [TemporalBlock(in_ch, out_ch, kernel_size, stride=1,\n",
    "                                     dilation=dilation, padding=padding,\n",
    "                                     dropout=dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, features) → lo ponemos (batch, features, seq_len)\n",
    "        x = x.transpose(1, 2)\n",
    "        y = self.network(x)\n",
    "        # devolvemos (batch, out_ch, seq_len)\n",
    "        return y\n",
    "\n",
    "class TCNClassifier(nn.Module):\n",
    "    \"\"\"TCN seguido de pooling global y capa de salida.\"\"\"\n",
    "    def __init__(self, input_dim, num_classes, num_channels, kernel_size=3, dropout=0.2):\n",
    "        \"\"\"\n",
    "        input_dim: dimensión de cada vector temporal (features)\n",
    "        num_classes: número de clases de salida\n",
    "        num_channels: lista de canales en cada bloque, p.ej. [128, 128, 128]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tcn = TemporalConvNet(input_dim, num_channels,\n",
    "                                   kernel_size=kernel_size,\n",
    "                                   dropout=dropout)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(num_channels[-1], num_classes)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        \"\"\"\n",
    "        x: tensor (batch, seq_len, input_dim)\n",
    "        lengths: opcional, no usado aquí\n",
    "        \"\"\"\n",
    "        y = self.tcn(x)                   # (batch, C, seq_len)\n",
    "        y = self.global_pool(y).squeeze(-1)  # (batch, C)\n",
    "        out = self.fc(y)                  # (batch, num_classes)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22020521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        # Capa convolucional 1D causal con padding = (kernel_size-1)*dilación (para asegurar causalidad)\n",
    "        self.conv1 = weight_norm(nn.Conv1d(in_channels, out_channels, kernel_size, \n",
    "                                           padding=(kernel_size-1)*dilation, dilation=dilation))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        # Segunda capa convolucional en el bloque (otro nivel de no linealidad)\n",
    "        self.conv2 = weight_norm(nn.Conv1d(out_channels, out_channels, kernel_size, \n",
    "                                           padding=(kernel_size-1)*dilation, dilation=dilation))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        # Combinamos las capas en un bloque secuencial\n",
    "        self.net = nn.Sequential(self.conv1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.relu2, self.dropout2)\n",
    "        # Conexión residual: si cambia el número de canales, ajustamos con conv 1x1\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Propagación hacia adelante del bloque temporal.\n",
    "        Entrada x de tamaño (batch, in_channels, seq_len).\n",
    "        \"\"\"\n",
    "        out = self.net(x)\n",
    "        # Recorte para causalidad: después de conv con padding, las salidas más allá de la longitud original se descartan\n",
    "        if self.conv1.padding[0] > 0:\n",
    "            out = out[:, :, :-self.conv1.padding[0]]  # elimina \"efecto futuro\"\n",
    "        # Suma residual (skip connection)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)  # activación ReLU tras sumar residual\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, input_channels, channel_sizes, kernel_size=3, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(channel_sizes)\n",
    "        # Construye múltiples bloques temporales con dilaciones crecientes (potencias de 2)\n",
    "        for i in range(num_levels):\n",
    "            in_ch = input_channels if i == 0 else channel_sizes[i-1]\n",
    "            out_ch = channel_sizes[i]\n",
    "            dilation = 2 ** i  # dilatación creciente por nivel (1, 2, 4, ...)\n",
    "            layers.append(TemporalBlock(in_ch, out_ch, kernel_size, dilation, dropout))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pasa la entrada a través de la pila de bloques temporales\n",
    "        return self.network(x)\n",
    "\n",
    "class TCNClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, channel_sizes=[32, 32, 32], kernel_size=3, dropout=0.2):\n",
    "        \"\"\"\n",
    "        input_dim: número de características de entrada por tiempo (ej: dimensión del embedding por frame).\n",
    "        num_classes: número de clases de salida (ej: posibles zonas de tiro en el penalti).\n",
    "        channel_sizes: lista con el número de filtros en cada capa TCN.\n",
    "        \"\"\"\n",
    "        super(TCNClassifier, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_dim, channel_sizes, kernel_size, dropout)\n",
    "        # Capa lineal final para producir la predicción de clase a partir de la representación temporal\n",
    "        final_out_channels = channel_sizes[-1]\n",
    "        self.fc = nn.Linear(final_out_channels, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x tiene tamaño (batch, input_dim, seq_len).\n",
    "        \"\"\"\n",
    "        features = self.tcn(x)         # salida TCN: (batch, final_out_channels, seq_len)\n",
    "        final_feature = features[:, :, -1]  # tomamos la característica del último paso temporal (último frame)\n",
    "        out = self.fc(final_feature)   # predicción de la clase\n",
    "        return out\n",
    "\n",
    "# ==== Ejemplo de instanciación y uso ====\n",
    "batch_size = 8\n",
    "seq_len = 30       # por ejemplo, 30 frames de entrada\n",
    "input_dim = 50      # 50 características por frame (ej: coordenadas, ángulos, etc.)\n",
    "num_classes = 5     # 5 posibles zonas de lanzamiento (clases)\n",
    "\n",
    "model = TCNClassifier(input_dim, num_classes, channel_sizes=[32, 32, 64], kernel_size=3, dropout=0.3)\n",
    "# Datos de ejemplo aleatorios\n",
    "example_input = torch.rand(batch_size, input_dim, seq_len)  # tensor de tamaño (8, 50, 30)\n",
    "logits = model(example_input)  # salida del modelo (8, 5) sin activar (logits de clase)\n",
    "print(logits.shape)  # debería ser [8, 5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b1434",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "## Modelo Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Transformer con atención temporal\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        model_dim=256,\n",
    "        n_heads=4,\n",
    "        num_layers=2,\n",
    "        ff_dim=512,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        \"\"\"\n",
    "        input_dim: dimensión D del embedding sin pooling (secuencia)\n",
    "        model_dim: dimensión interna del transformer\n",
    "        n_heads: número de cabezas de atención\n",
    "        num_layers: número de capas Encoder\n",
    "        ff_dim: dimensión del feed-forward\n",
    "        dropout: dropout en capas Encoder\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Proyección de la dimensión de entrada al espacio model_dim\n",
    "        self.token_proj = nn.Linear(input_dim, model_dim)\n",
    "        # Capa TransformerEncoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=model_dim,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # Clasificador al token de posición 0 (CLS) o media de salidas\n",
    "        self.classifier = nn.Linear(model_dim, 3)\n",
    "\n",
    "    def forward(self, x, lengths=None):\n",
    "        \"\"\"\n",
    "        x: FloatTensor (B, T, D)\n",
    "        lengths: LongTensor (B,) opcional para masking\n",
    "        \"\"\"\n",
    "        # x → proyección\n",
    "        x = self.token_proj(x)  # (B, T, model_dim)\n",
    "\n",
    "        # Generar máscara de padding si lengths dado\n",
    "        if lengths is not None:\n",
    "            max_len = x.size(1)\n",
    "            mask = torch.arange(max_len, device=lengths.device) \\\n",
    "                   .unsqueeze(0) >= lengths.unsqueeze(1)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        # TransformerEncoder\n",
    "        out = self.transformer(x, src_key_padding_mask=mask)  # (B, T, model_dim)\n",
    "\n",
    "        # Agregado temporal: tomamos token 0 como representativo\n",
    "        cls_token = out[:, 0, :]  # (B, model_dim)\n",
    "        return self.classifier(cls_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789c355e",
   "metadata": {},
   "source": [
    "\n",
    "## Preparación de datos, split y bucle de entrenamiento: Transformer\n",
    "Con atención atemporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a1cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk 2: Collate function y preparación de datos para Transformer\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_sequences(batch):\n",
    "    \"\"\"\n",
    "    Recibe una lista de tuplas (tensor_seq, label).\n",
    "    Devuelve:\n",
    "      - padded: FloatTensor (B, T_max, D)\n",
    "      - lengths: LongTensor (B,)\n",
    "      - labels: LongTensor (B,)\n",
    "    \"\"\"\n",
    "    seqs, labels = zip(*batch)\n",
    "    lengths = torch.tensor([s.size(0) for s in seqs], dtype=torch.long)\n",
    "    padded  = pad_sequence(seqs, batch_first=True)\n",
    "    labels  = torch.tensor(labels, dtype=torch.long)\n",
    "    return padded, lengths, labels\n",
    "\n",
    "def prepare_transformer_data(df, norm='minmax', test_size=0.2):\n",
    "    \"\"\"\n",
    "    Construye listas de muestras para train y test:\n",
    "      - norm: 'minmax' o 'l2'\n",
    "    Cada muestra es (tensor_seq, label).\n",
    "    \"\"\"\n",
    "    feat_cols = [c for c in df.columns if c.startswith('feat_')]\n",
    "    seqs, labs = [], []\n",
    "    for vid, grp in df.groupby('video_ID'):\n",
    "        arr = grp[feat_cols].values.astype(np.float32)  # (T, D)\n",
    "        seqs.append(arr)\n",
    "        labs.append(int(grp['shoot_zone'].iloc[0]))\n",
    "    # Normalización\n",
    "    if norm == 'minmax':\n",
    "        all_frames = np.vstack(seqs)  # (sum_T, D)\n",
    "        scaler = MinMaxScaler().fit(all_frames)\n",
    "        seqs = [scaler.transform(s) for s in seqs]\n",
    "    else:  # 'l2'\n",
    "        seqs = [s / np.linalg.norm(s, axis=1, keepdims=True) for s in seqs]\n",
    "    # Split estratificado\n",
    "    idx = list(range(len(seqs)))\n",
    "    idx_tr, idx_te = train_test_split(idx,\n",
    "                                      test_size=test_size,\n",
    "                                      stratify=labs,\n",
    "                                      random_state=42)\n",
    "    # Convertir a lista de tuplas (tensor_seq, label)\n",
    "    train_list = [(torch.from_numpy(seqs[i]), labs[i]) for i in idx_tr]\n",
    "    test_list  = [(torch.from_numpy(seqs[i]), labs[i]) for i in idx_te]\n",
    "    return train_list, test_list\n",
    "\n",
    "\n",
    "def run_training_transformer(model, train_loader, test_loader, epochs=20, lr=1e-3):\n",
    "    \"\"\"\n",
    "    Función de entrenamiento específica para el modelo Transformer\n",
    "    Args:\n",
    "        model: Instancia de TransformerClassifier\n",
    "        train_loader: DataLoader con datos de entrenamiento \n",
    "        test_loader: DataLoader con datos de test\n",
    "        epochs: Número de épocas de entrenamiento\n",
    "        lr: Learning rate para el optimizador\n",
    "    Returns:\n",
    "        history: Diccionario con métricas de entrenamiento\n",
    "    \"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    history = {'train_loss': [], 'test_acc': [], 'test_f1': []}\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        # --- Fase de entrenamiento ---\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for xb, lengths, yb in train_loader:\n",
    "            xb = xb.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            yb = yb.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb, lengths)\n",
    "            loss = loss_fn(out, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * yb.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        history['train_loss'].append(avg_loss)\n",
    "\n",
    "        # --- Fase de evaluación ---\n",
    "        model.eval()\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for xb, lengths, yb in test_loader:\n",
    "                xb = xb.to(device)\n",
    "                lengths = lengths.to(device)\n",
    "                outputs = model(xb, lengths)\n",
    "                preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_labels.append(yb.numpy())\n",
    "\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        \n",
    "        acc = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        history['test_acc'].append(acc)\n",
    "        history['test_f1'].append(f1)\n",
    "\n",
    "        print(f\"Época {ep:02d}/{epochs} | \"\n",
    "                f\"loss {avg_loss:.4f} | \"\n",
    "                f\"acc {acc:.4f} | \"\n",
    "                f\"f1_macro {f1:.4f}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e5359",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fe94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Configuración\n",
    "\n",
    "DATA_DIR = \"Gait_Embeddings_good\"\n",
    "NORMS = ['minmax', 'l2']\n",
    "EPOCHS = 100  # Aumentado para mejor convergencia\n",
    "BATCH_SIZE = 32  # Tamaño de batch para entrenamiento\n",
    "LR = 1e-3\n",
    "MODEL_DIM = 256  # Dimensión del transformer\n",
    "N_HEADS = 8  # Número de cabezas de atención\n",
    "N_LAYERS = 2  # Capas del encoder\n",
    "\n",
    "results_transformer = []\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    if not fname.endswith('.csv'):\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\n--- Entrenando Transformer con {fname} ---\")\n",
    "    df = pd.read_csv(os.path.join(DATA_DIR, fname))\n",
    "    \n",
    "    for norm in NORMS:\n",
    "        # Preparar datos\n",
    "        train_list, test_list = prepare_transformer_data(df, norm=norm)\n",
    "        tr_loader = DataLoader(train_list, \n",
    "                             batch_size=BATCH_SIZE, \n",
    "                             shuffle=True, \n",
    "                             collate_fn=collate_sequences)\n",
    "        te_loader = DataLoader(test_list, \n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             collate_fn=collate_sequences)\n",
    "\n",
    "        # Crear y entrenar modelo\n",
    "        model = TransformerClassifier(\n",
    "            input_dim=df.filter(like='feat_').shape[1],\n",
    "            model_dim=MODEL_DIM,\n",
    "            n_heads=N_HEADS,\n",
    "            num_layers=N_LAYERS,\n",
    "            ff_dim=MODEL_DIM * 4,  # Típicamente 4x model_dim\n",
    "            dropout=0.1\n",
    "        ).to(DEVICE)\n",
    "        \n",
    "        history = run_training_transformer(\n",
    "            model, \n",
    "            tr_loader, \n",
    "            te_loader,\n",
    "            epochs=EPOCHS, \n",
    "            lr=LR\n",
    "        )\n",
    "\n",
    "        # Guardar resultados\n",
    "        results_transformer.append({\n",
    "            'extractor': fname,\n",
    "            'model': 'Transformer',\n",
    "            'normalization': norm,\n",
    "            'accuracy': history['test_acc'][-1],\n",
    "            'f1_macro': history['test_f1'][-1]\n",
    "        })\n",
    "\n",
    "# Guardar resultados\n",
    "df_results = pd.DataFrame(results_transformer)\n",
    "df_results.to_csv('transformer_results.csv', index=False)\n",
    "print(\"\\n✅ Resultados Transformer guardados en transformer_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6e756",
   "metadata": {},
   "source": [
    "## Métricas posibles a usar\n",
    "Precisión global (Accuracy)\n",
    "\n",
    "F₁‐score macro\n",
    "Matriz de confusión\n",
    "\n",
    "Precisión (Precision) por clase\n",
    "\n",
    "Exhaustividad (Recall) por clase\n",
    "\n",
    "Balanced accuracy (accuracy balanceada)\n",
    "\n",
    "Matthew’s Correlation Coefficient (MCC)\n",
    "\n",
    "Curva ROC y AUC multiclass (one-vs-rest)\n",
    "\n",
    "Log-Loss (Cross-Entropy Loss)\n",
    "\n",
    "Brier Score\n",
    "\n",
    "Cohen’s Kappa\n",
    "\n",
    "Top-k accuracy (por ejemplo Top-2)\n",
    "\n",
    "Time-to-decision (número medio de frames o ms antes del golpeo en que la predicción es estable)\n",
    "\n",
    "Área bajo la curva Accuracy vs. Earliness\n",
    "\n",
    "Tiempo de inferencia por muestra (latencia)\n",
    "\n",
    "Número de parámetros / FLOPS / uso de memoria"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pln",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
